{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyft Competition : Uderstanding the data (한글 번역본)\n",
    "\n",
    "* competition: Lyft 3D Object Detection for Autonomous Vehicles\n",
    "* original kernel: https://www.kaggle.com/tarunpaparaju/lyft-competition-understanding-the-data\n",
    "* share: [Junghyun Park](https://github.com/parkjh688)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "<img src=\"./images/image1.jpg\" alt=\"image1\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='grey'>이 커널에서, 나는 이미지, LiDAR, 포인트클라우드를 포함한 데이터셋의 구성요소의 의미와 직관에 대해 설명할 것 입니다. 이러한 개념에 대한 이론을 살펴본 후, 이 데이터셋에서 정보를 더 쉽게 쿼리할 수 있는 컴팩트 형식으로 패키징할 수 있는 방법을 보여줄 것 입니다. 그리고 마지막으로, 이 데이터를 어떻게 시각화하고 탐구하는지를 matplotlib의 플롯과 그래프를 사용하여 보여줄 것 입니다.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "* [NuScences DevKit ~ by Lyft](https://github.com/lyft/nuscenes-devkit)\n",
    "* [EDA - 3D Object Detection Challenge ~ by beluga](https://www.kaggle.com/gaborfodor/eda-3d-object-detection-challenge)\n",
    "* [Lyft: EDA, Animations, generating CSVs ~ by xhulu](https://www.kaggle.com/xhlulu/lyft-eda-animations-generating-csvs)\n",
    "* [Lidar - Wikipedia](https://en.wikipedia.org/wiki/Lidar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>이 커널이 흥미롭다면, 좋아요(upvote)를 눌러주세요. 좋아요는 나에게 더 많은 양질의 콘텐츠를 생산하도록 동기를 부여해줍니다 :)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**자율주행 자동차를 시작해봅시다!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 커널의 기술적인 부분들을 시작해보기 전에, 자율주행 자동차에 대한 재미있는 비디오를 하나 봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><iframe width=\"700\" height=\"400\" src=\"https://www.youtube.com/embed/tlThdr3O5Qo?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<center><iframe width=\"700\" height=\"400\" src=\"https://www.youtube.com/embed/tlThdr3O5Qo?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe></center>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자동차가 쉽게 교대로, 차선을 바꾸거나, 빨간 신호등에서 정지하는 등의 기능을 할 수 있다는 것을 영상에서 볼 수 있습니다. 이것은 자동차가 이미지나 LiDAR 데이터와 같은 센서의 정보를 사용하여 3D 공간에서 물체를 정확하게 인식할 수 있기 때문에 가능한 일입니다. 이제 이러한 형태의 데이터가 이론적으로 무엇을 의미하는지 살펴본 다음, 커널에서 시각화해볼 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. scene - 주어진 환경에서의 25-45초의 차량 주행으로 구성됨. 각각의 scence 들은 여러 개의 샘플로 구성되어 있음.\n",
    "2. sample - 특정 시간, 특정 인스턴스에 대한 스냅샷. 각 sample에는 object가 어노테이션(annotation) 되어있다.\n",
    "3. sample_data - 차량의 특정 센서에서 수집한 데이터.\n",
    "4. sample_annotation - 우리가 관심 있는 대상의 annotation된 인스턴스.\n",
    "5. instance - 우리가 관찰한 모든 object 인스턴스의 리스트.\n",
    "6. category - object 카테고리(예: 차, 사람)\n",
    "7. attribute - 카테고리가 동일하게 유지되는 동안 변경될 수 있는 인스턴스의 속성.\n",
    "8. visibility - 현재 사용 안함\n",
    "9. sensor - 센서 종류\n",
    "10. calibrated sensor - 특정 차량에서 캘리브레이션(calibration)된 특정 센서.\n",
    "11. ego_pose - 특정 시간대 Ego vehicle의 상태(pose)\n",
    "12. log - 데이터와 관련된 로그\n",
    "13. map - 위에서 본(top-down view) binary semantic mask들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 각 스냅샷은 두 가지 형태의 정보로 구성됩니다: **이미지 데이터와 LiDAR 데이터**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터는 일반적입니다. .jpeg 포맷은 상당히 이해하기 쉽습니다. 각 이미지들은 단순하게 이미지를 형성하는 RGB 컬러 3개의 채널로 구성되어 있습니다:Red (R), Blue (B), and Green (G). 이 컬러 채널들을 겹쳐서 하나의 색이 있는 이미지를 만들어 냅니다. 따라서 이미지들은 4개의 차원을 가진 텐서(Tensor)로 저장되어 있습니다: (batch_size, channels, width, height)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 나는 대부분의 사람들은 친숙하지 않을 LiDAR 데이터에 대해 이야기 하려고 합니다. 나는 LiDAR 데이터가 어떻게 수집되고 저장되는지에 대해 설명할 것이고, 이 데이터 포맷이 가지고 있는 의미에 대해서 이야기할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is LiDAR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LiDAR(Light Detection and Ranging)는 주변의 정확한 3D 표현을 생성하기 위해 사용되는 방법이며, 이를 달성하기 위해 레이저 빛을 이용합니다. 기본적으로 3D 타겟은 레이저 광선(직선의 빛)으로 비춰지고 반사광은 센서에 의해 수집됩니다. 그리고 빛이 센서에 반사되는 데 필요한 시간을 계산합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 센서들은 물체의 다른 부분으로부터 빛을 수집하며, 이 센서에 의해 기록된 시간은 다를 것입니다. 센서가 계산한 시간의 차는 물체의 깊이를 계산하는 데 사용될 수 있습니다. 이 깊이 정보는 이미지의 2D 표현과 결합되어 객체의 정확한 3D 표현을 제공하게 됩니다. 이 과정은 실제 인간의 시각과 비슷합니다. 우리의 두 눈은 2D로 관찰하고, 이 두 개의 정보를 결합해서 3D 지도(depth perception)를 형성합니다. 이것이 바로 인간이 우리 주변의 세상을 이렇게 감지하는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 기술은, 많은 실제 시나리오에서 3D 표현을 만드는 데 사용됩니다. 예를 들어, 농장에서 씨앗을 뿌리고 잡초를 제거하는 것을 돕기 위해 사용됩니다. 움직이는 로봇은 LiDAR를 사용하여 주변 환경에 대한 3D 지도를 만들고 이 지도를 사용하여 장애물을 피하고 임무를 완수합니다. 이 기술은 고고학에서도 사용됩니다. LiDAR는 2D 유물(artifact) 스캔본의 3D 렌더링하는데 사용됩니다. 이것은 어떤 방법으로도 유물을 발굴할 수 없을 때 유물의 3차원 형상을 정확히 알 수 있게 해줍니다. 마지막으로, LiDAR는 또한 해저와 접근이 불가능한 다른 지형들의 고품질 3D 지도를 만드는 데 사용될 수 있어 지질학자들과 해양학자들에게 매우 유용합니다. 아래는 LiDAR을 사용하여 생성된 해저의 3D 지도입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image2.jpg\" alt=\"image2\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "물론, 자율주행차는 이 기술을 사용하여 주변의 물체를 3D로 식별하고, 이 물체의 속도와 방향을 추정합니다. 이 포괄적인 3D 지도는 복잡한 환경에서도 차량을 탐색할 수 있도록 상세한 정보를 제공합니다. 아래는 LiDAR를 장착한 드론이 나오는 영상입니다. 위에서 언급한 과정을 이용하여 자동적으로 그 주위에 3D 지도를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><iframe width=\"700\" height=\"400\" src=\"https://www.youtube.com/embed/x7De3tCb3_A?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<center><iframe width=\"700\" height=\"400\" src=\"https://www.youtube.com/embed/x7De3tCb3_A?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe></center>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "## How does LiDAR work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image3.gif\" alt=\"image3\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 GIF는 LiDAR가 어떻게 작동하는지 대략적으로 보여주고 있습니다. 기본적으로, 레이저 광선은 레이저에 의해 사방으로 발사됩니다. 레이저 빔은 경로에 있는 물체를 반사하고 반사된 빛은 센서에 의해 수집됩니다. 현재 Flash LiDAR 카메라라고 불리는 특별한 장치가 이러한 센서의 정보를 사용하여 3D 지도를 만드는 데 사용되고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flash LiDAR Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image4.jpg\" alt=\"image4\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 이미지에 나타난 장치를 Flash LiDAR 카메라라고 합니다. Flash LiDAR 카메라의 초점면에는 3D 모델을 만들 수 있는 \"depth(깊이)\"와 \"intensity(강도)\" 픽셀의 행과 열이 있습니다. 각각의 픽셀은 레이저 펄스가 목표물에 부딪히고 센서로 돌아오는 데 걸리는 시간과 레이저 펄스에 의해 접촉되는 물체의 깊이, 위치, 반사 강도를 기록합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flash LiDAR 단일 펄스로 시야를 밝히는 단일 광원을 사용합니다. 컬러 대신 거리 사진을 찍는 카메라처럼."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "온보드 조명 소스(onboard source of illumination)는 Flash LiDAR를 활성 센서로 만듭니다. 반환되는 신호는 내장된 알고리즘에 의해 처리되어 센서의 시야 내에서 물체와 지형 형상의 거의 즉각적인 3D 렌더링을 생성하게 됩니다. 레이저 펄스 반복 주파수는 높은 해상도와 정확도를 가진 3D 비디오를 생성하기에 충분합니다. 센서의 프레임률이 높기 때문에 자율주행 등 실시간 시각화가 필요한 다양한 어플리케이션에 유용한 툴입니다. 대상 환경의 3D 고도 메쉬를 즉시 반환함으로써, 무인자동차가 속도 조정, 제동, 조향 등과 관련된 결정을 내릴 수 있게 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 형태의 카메라는 자율주행차 상단에 부착되어 있으며, 이 차들은 주행 중 이를 이용해 움직입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "이제 LiDAR가 무엇인지, 어떻게 작동하는지 명확하게 알게되었으므로 데이터셋을 바로 시각화해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "## Visualizing the data¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lyft_dataset_sdk 및 필요한 라이브러리 설치 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "우리는 이미지와 LiDAR 데이터를 쉽게 시각화하기 위해 lyft_dataset_sdk 라이브러리가 필요합니다. 간단한 pip install 명령만 있으면 설치는 끝납니다. 또한 인터랙티브(interactive) 플롯을 생성하기 위해 chart_studio 라이브러리를 설치할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lyft_dataset_sdk\n",
      "  Downloading lyft_dataset_sdk-0.0.8-py2.py3-none-any.whl (32 kB)\n",
      "Collecting scikit-learn>=0.19.2\n",
      "  Using cached scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-5.3.5-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 755 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow>=5.2.0\n",
      "  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyquaternion>=0.9.5\n",
      "  Downloading pyquaternion-0.9.5-py3-none-any.whl (14 kB)\n",
      "Collecting opencv-python>=3.4.2.17\n",
      "  Downloading opencv_python-4.2.0.32-cp37-cp37m-manylinux1_x86_64.whl (28.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.2 MB 152 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-4.5.0-py2.py3-none-any.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 104.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Shapely>=1.6.4.post2\n",
      "  Downloading Shapely-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 37.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.25.0\n",
      "  Downloading tqdm-4.42.1-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 1.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools>=3.1.0\n",
      "  Using cached cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 933 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (10.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.0 MB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flake8\n",
      "  Downloading flake8-3.7.9-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 1.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.1.0\n",
      "  Using cached scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Collecting fire\n",
      "  Downloading fire-0.2.1.tar.gz (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 859 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.14.5\n",
      "  Downloading numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting black\n",
      "  Downloading black-19.10b0-py36-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 1.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Using cached joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "Collecting py>=1.5.0\n",
      "  Downloading py-1.8.1-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[K     |████████████████████████████████| 83 kB 379 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "  Downloading packaging-20.1-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: wcwidth in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from pytest->lyft_dataset_sdk) (0.1.8)\n",
      "Collecting more-itertools>=4.0.0\n",
      "  Downloading more_itertools-8.2.0-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 289 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pluggy<1.0,>=0.12\n",
      "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from pytest->lyft_dataset_sdk) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from pytest->lyft_dataset_sdk) (1.5.0)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: six in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from plotly->lyft_dataset_sdk) (1.14.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Using cached pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from matplotlib->lyft_dataset_sdk) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
      "Requirement already satisfied: entrypoints<0.4.0,>=0.3.0 in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from flake8->lyft_dataset_sdk) (0.3)\n",
      "Collecting pycodestyle<2.6.0,>=2.5.0\n",
      "  Downloading pycodestyle-2.5.0-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 1.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
      "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
      "Collecting pyflakes<2.2.0,>=2.1.0\n",
      "  Downloading pyflakes-2.1.1-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 1.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hProcessing /home/eden/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp37-none-any.whl\n",
      "Collecting regex\n",
      "  Downloading regex-2020.1.8-cp37-cp37m-manylinux2010_x86_64.whl (690 kB)\n",
      "\u001b[K     |████████████████████████████████| 690 kB 37.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting appdirs\n",
      "  Downloading appdirs-1.4.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typed-ast>=1.4.0\n",
      "  Downloading typed_ast-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (737 kB)\n",
      "\u001b[K     |████████████████████████████████| 737 kB 17.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toml>=0.9.4\n",
      "  Downloading toml-0.10.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting click>=6.5\n",
      "  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 1.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pathspec<1,>=0.6\n",
      "  Downloading pathspec-0.7.0-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->lyft_dataset_sdk) (2.1.0)\n",
      "Requirement already satisfied: setuptools in /home/eden/anaconda3/envs/lyft3d/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->lyft_dataset_sdk) (45.1.0.post20200127)\n",
      "Building wheels for collected packages: fire, retrying\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103528 sha256=b765e03da481291beeee12925c3b1977a075bcc387d6046c78704bc1d12749c0\n",
      "  Stored in directory: /home/eden/.cache/pip/wheels/a8/6d/a8/d81d42414b24203fc8beb0452deab949ba62fcfb8c7a49e4b6\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11430 sha256=3a984243906bb46a7906e22643a5f271c1ad9d57b320d81e4f8bfb49a46d7b27\n",
      "  Stored in directory: /home/eden/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "Successfully built fire retrying\n",
      "Installing collected packages: numpy, scipy, joblib, scikit-learn, py, pyparsing, packaging, more-itertools, pluggy, pytest, Pillow, pyquaternion, opencv-python, retrying, plotly, Shapely, tqdm, cachetools, kiwisolver, cycler, matplotlib, pytz, pandas, pycodestyle, mccabe, pyflakes, flake8, termcolor, fire, regex, appdirs, typed-ast, toml, click, pathspec, black, lyft-dataset-sdk\n",
      "Successfully installed Pillow-7.0.0 Shapely-1.7.0 appdirs-1.4.3 black-19.10b0 cachetools-4.0.0 click-7.0 cycler-0.10.0 fire-0.2.1 flake8-3.7.9 joblib-0.14.1 kiwisolver-1.1.0 lyft-dataset-sdk-0.0.8 matplotlib-3.1.3 mccabe-0.6.1 more-itertools-8.2.0 numpy-1.18.1 opencv-python-4.2.0.32 packaging-20.1 pandas-1.0.0 pathspec-0.7.0 plotly-4.5.0 pluggy-0.13.1 py-1.8.1 pycodestyle-2.5.0 pyflakes-2.1.1 pyparsing-2.4.6 pyquaternion-0.9.5 pytest-5.3.5 pytz-2019.3 regex-2020.1.8 retrying-1.3.3 scikit-learn-0.22.1 scipy-1.4.1 termcolor-1.1.0 toml-0.10.0 tqdm-4.42.1 typed-ast-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lyft_dataset_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터 탐구를 하는데 필요한 다른 라이브러리도 가져와 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Tuple, List\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "from PIL import Image\n",
    "\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib import animation, rc\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.offline import plot, init_notebook_mode\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "from pyquaternion import Quaternion\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lyft_dataset_sdk.utils.map_mask import MapMask\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, box_in_image, BoxVisibility\n",
    "from lyft_dataset_sdk.utils.geometry_utils import view_points, transform_matrix\n",
    "from pathlib import Path\n",
    "\n",
    "import struct\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import reduce\n",
    "from typing import Tuple, List, Dict\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "**데이터셋 경로(path) 맞추기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/3d-object-detection-for-autonomous-vehicles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습 데이터가 저장되어 있는 데이터 프레임 가져오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "sample_submission = pd.read_csv(DATA_PATH + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**카테고리별로 데이터 그룹짓기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22680/22680 [00:01<00:00, 19501.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Taken from https://www.kaggle.com/gaborfodor/eda-3d-object-detection-challenge\n",
    "\n",
    "object_columns = ['sample_id', 'object_id', 'center_x', 'center_y', 'center_z',\n",
    "                  'width', 'length', 'height', 'yaw', 'class_name']\n",
    "objects = []\n",
    "for sample_id, ps in tqdm(train.values[:]):\n",
    "    object_params = ps.split()\n",
    "    n_objects = len(object_params)\n",
    "    for i in range(n_objects // 8):\n",
    "        x, y, z, w, l, h, yaw, c = tuple(object_params[i * 8: (i + 1) * 8])\n",
    "        objects.append([sample_id, i, x, y, z, w, l, h, yaw, c])\n",
    "train_objects = pd.DataFrame(\n",
    "    objects,\n",
    "    columns = object_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**숫자인 피쳐(features) str에서 float32로 바꾸기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['object_id', 'center_x', 'center_y', 'center_z', 'width', 'length', 'height', 'yaw']\n",
    "train_objects[numerical_cols] = np.float32(train_objects[numerical_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>object_id</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>center_z</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>height</th>\n",
       "      <th>yaw</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.282959</td>\n",
       "      <td>698.196899</td>\n",
       "      <td>-18.047768</td>\n",
       "      <td>2.064</td>\n",
       "      <td>5.488</td>\n",
       "      <td>2.053</td>\n",
       "      <td>2.604164</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2691.997559</td>\n",
       "      <td>660.801636</td>\n",
       "      <td>-18.674259</td>\n",
       "      <td>1.818</td>\n",
       "      <td>4.570</td>\n",
       "      <td>1.608</td>\n",
       "      <td>-0.335176</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2713.607422</td>\n",
       "      <td>694.403503</td>\n",
       "      <td>-18.589972</td>\n",
       "      <td>1.779</td>\n",
       "      <td>4.992</td>\n",
       "      <td>1.620</td>\n",
       "      <td>2.579456</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2679.986816</td>\n",
       "      <td>706.910156</td>\n",
       "      <td>-18.349594</td>\n",
       "      <td>1.798</td>\n",
       "      <td>3.903</td>\n",
       "      <td>1.722</td>\n",
       "      <td>2.586166</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2659.352051</td>\n",
       "      <td>719.417480</td>\n",
       "      <td>-18.442999</td>\n",
       "      <td>1.936</td>\n",
       "      <td>4.427</td>\n",
       "      <td>1.921</td>\n",
       "      <td>2.601799</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sample_id  object_id     center_x  \\\n",
       "0  db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...        0.0  2680.282959   \n",
       "1  db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...        1.0  2691.997559   \n",
       "2  db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...        2.0  2713.607422   \n",
       "3  db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...        3.0  2679.986816   \n",
       "4  db8b47bd4ebdf3b3fb21598bb41bd8853d12f8d2ef25ce...        4.0  2659.352051   \n",
       "\n",
       "     center_y   center_z  width  length  height       yaw class_name  \n",
       "0  698.196899 -18.047768  2.064   5.488   2.053  2.604164        car  \n",
       "1  660.801636 -18.674259  1.818   4.570   1.608 -0.335176        car  \n",
       "2  694.403503 -18.589972  1.779   4.992   1.620  2.579456        car  \n",
       "3  706.910156 -18.349594  1.798   3.903   1.722  2.586166        car  \n",
       "4  719.417480 -18.442999  1.936   4.427   1.921  2.601799        car  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_objects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "**첫 번째 데이터 탐구**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 나는 이 특정 데이터 프레임의 데이터를 살펴보고 그것으로부터 유용한 인사이트를 얻을 수 있는지 알아볼 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**center_x와 center_y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "center_x와 center_y는 객체 위치의 중심(bounding volume)의 x, y 좌표에 해당합니다. 이 좌표는 x-y평면에 있는 객체의 위치를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**center_x와 center_y의 분포**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image5.png\" alt=\"image5\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 다이어그램에서, 보라색은 center_y의 분포를, 주황색은 center_x의 분포를 나타냅니다. 위의 다이어그램에서 알 수 있듯이, 우리는 center_x, center_y 모두 여러개의 피크를 가지며 이것으로부터 멀티모달(multimodal)임을 알 수 있습니다. 두 분포 모두 right skewed되어 있습니다. 하지만 center_y의 분포(보라색)은 center_x(주황색)의 분포보다 훨씬 더 치우쳐져(skewed) 있습니다. center_x 분포가 더 고르게 분포되어 있기 때문에 알 수 있었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 물체가 x축을 따라 매우 고르게 펼쳐지지만 y축은 아니라는 것을 나타냅니다. 도로 폭이 작아 자동차의 카메라가 왼쪽이나 오른쪽의 물체를 쉽게 감지할 수 있기 때문일 것입니다. 그러나 도로의 길이가 폭보다 훨씬 크고, 카메라의 시야가 이 각도에서 차단될 가능성이 높기 때문에 카메라는 앞이나 뒤쪽으로 좁게 물체를 찾을 수 있었을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "**center_x와 center_y의 관계**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KDE Plot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image6.png\" alt=\"image6\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 KDE 그림에서, center_x와 center_y는 다소 부정적인 상관관계를 가지고 있는 것 같이 보입니다. 이것은 아마도, 다시 한 번, 카메라 시스템의 한계 때문에 일일 것이라고 생각됩니다. 카메라의 앞쪽에 있으면서 옆으로는 가까운 물체를 감지할 수 있습니다. 그리고, 그것은 또한 멀지 않은 물체를 감지할 수 있으면서, 옆으로 멀리 있는 물체는 감지할 수 없습니다. **그러나 카메라는 앞쪽으로 멀리있으면서 옆으로도 멀리 있는 물체를 감지할 수 없습니다.** 그렇게 때문에 훨씬 앞쪽에 있고 옆으로도 멀리 떨어져 있는 물체는 전혀 검출되지 않고, 그 조건 중 하나(또는 둘 다 아닐 때)를 만족시키는 물체만 검출합니다. 이것은 center_x와 center_y 사이에 부정적인 관계를 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**center_z**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "center_z는 객체 위치의 중심(bounding volume)의 xz좌표에 해당한다. 이 좌표는 x-y 평면 위에 있는 물체의 높이를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**center_z의 분포**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image7.png\" alt=\"image7\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 다이어그램에서, 우리는 center_z의 분포가 극히 높은 양의(우측) 치우침을 가지고 있으며 -20 마크(평균값에 근접한 값)를 중심으로 군집되어 있음을 알 수 있습니다. center_z의 분산(스프레드)은 center_x와 center_y보다 상당히 작다는 것을 알 수 있습니다. 이것은 아마도 대부분의 물체가 도로의 평평한 평면에 매우 가깝기 때문에 카메라 위(또는 아래)의 물체의 높이에는 큰 변화가 없기 때문일 것입니다. 개체의 x와 y의 좌표는  큰 분산이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 카메라가 무인 자동차 위에 부착돼 있어 대부분의 z 좌표는 음수입니다. 그래서, 대부분의 경우 카메라는 물체를 보기 위해 \"아래를 내려다봐야\" 합니다. 따라서 카메라와 상대적인 물체의 높이 혹은 z 좌표가 일반적으로 음수인 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**yaw**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yaw**는 z축을 중심으로 한 각도로, 지상에 있을 때 차량/경계 박스의 앞부분이 가리키는 방향을 'yaw'로 만듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yaw의 분포**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image8.png\" alt=\"image8\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 다이어그램에서, 우리는 yaw의 분포가 대략 bimodal, 즉 분포에 2개의의 큰 피크(peaK)가 있음을 알 수 있습니다. 피크 중 하나는 약 0.5, 다른 하나는 약 2.5점 정도로 보입니다. mean은 1과 2(약 1.5) 사이라고 추정할 수 있습니다. 분포에는 뚜렷한 치우침(skew)이 없습니다. 대칭 위치에 있는 두 개의 피크는 치우침(skew)를 감소시키고, center_x, center_y, center_z의 분포보다 분포가 균형이 있게 해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**width**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "width는 간단히 놓여있는 물체의 bounding volume의 폭입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image9.png\" alt=\"image9\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 다이어그램에서, width는 대략 보통 약 2를 평균으로 하면서 양쪽에 일부 특이치가 있는 것으로 볼 수 있습니다. 대다수의 물체는(나중에 보게 되겠지만) 자동차로, 약 2 정도의 width을 이룹니다. 오른쪽의 특이치는 트럭이나 밴과 같은 큰 객체들을 나타내고, 왼쪽의 특이치는 보행자나 자전거와 같은 작은 물체를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**length**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "length는 간단히 놓여있는 물체의 bounding volume의 길이입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image10.png\" alt=\"image10\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 다이어그램에서, length는 강한 positive skew(rightward skew)를 가지고 있으며, 평균은 약 5이고, 어느 한쪽에는 약간의 특이치가 있다는 것을 알 수 있습니다. 대다수의 물체는(나중에 보게 되겠지만) 자동차로, 이것들은 길이 약 5를 이룹니다. 오른쪽의 특이치는 트럭이나 밴과 같은 큰 오브젝트들을 나타내고, 왼쪽의 특이치는 보행자나 자전거와 같은 작은 물체를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**height**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "height는 단순히 놓여 있는 경계 부피의 높이입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image11.png\" alt=\"image11\" style=\"width:500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 다이어그램에서, height는 평균이 약 2이면서 positive skew(rightward skew)를 가지고 있으며, 어느 한쪽에는 일부 특이치가 있음을 알 수 있습니다. 대다수의 물체는(나중에 보게 되겠지만) 자동차로, 이것들은 (정점에서) 약 2의 길이를 이룬다. 오른쪽의 특이치는 트럭이나 밴과 같은 큰 오브첵트들을 나타내고, 왼쪽의 특이치는 보행자나 자전거와 같은 작은 물체를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**카테고리별 객체의 빈도**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image12.png\" alt=\"image12\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 다이어그램에서, 데이터셋의 가장 일반적인 객체 클래스는 \"car\"라고 볼 수 있습니다. 캘리포니아 실리콘밸리의 팔로 알토 거리에서 찍은 사진이기 때문에 이것은 놀라운 일이 아닙니다. 그리고, 도로들에서 가장 일반적인 차량은 자동차들입니다. 다른 모든 물체들은 빈도 수로는 자동차 근처에도 못 따라 간다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**center_x** <i>**vs.**</i> **class_name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림에서, center_x 분포가 다른 객체들의 class_names에 대해 어떻게 변하는지 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image13.png\" alt=\"image13\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 바이올린 플롯에서, 트럭, 버스, 기타 차량을 포함한 대형 차량에 대한 center_x의 분포가 잘 퍼져 있음을 알 수 있습니다. 그들은 거의 비뚤어진 데가 없고 보행자와 자전거의 분포보다 더 잘 퍼져있습니다. 이는 아마도 이런 대형 차량들이 다른 차들과 더 먼 거리를 유지하는 경향이 있고, 소형차량들은 사고를 피하기 위해 이런 대형차들과 너무 가까이 있지 않기 때문일 것입니다. 따라서 평균 center_x는 버스나 트럭과 같은 대형 차량에 대해 분명히 더 큽니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이와는 대조적으로, 보행자나 자전거와 같은 작은 물체는 cneter_x 분포에 강한 positive skew(rightward)를 가지고 있습니다. 이러한 분포는 또한 대형 차량에 대한 분배보다 확실히 작은 평균을 가지고 있습니다. 보행자와 자전거 이용자들이 사고를 피하기 위해 자동차나 트럭으로 큰 거리를 유지할 필요가 없기 때문일 것입니다. 보통 빨간불이 켜지고, 차들이 멈췄을 때 도로를 건너기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image14.png\" alt=\"image14\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 박스 플롯에서, 바이올린 플롯에서 얻은 정보들과 같다는 것을 눈치챌 수 있습니다. 보행자나 자전거와 같은 작은 물체에 대한 중심_x 분포는 자동차, 트럭, 버스 같은 큰 물체에 비해 매우 낮은 평균값과 사분위수 값을 가진다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**center_y** <i>**vs.**</i> **class_name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 플롯에서, center_y의 분포가 class_names(다른 객체)에 어떻게 변하는지 탐구할 것 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/image15.png\" alt=\"image15\" style=\"width:600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 바이올린 플롯에서, 우리는 보행자와 자전거를 포함한 작은 물체에 대한 center_y의 분포는 트럭이나 버스 같은 큰 물체보다 더 큰 평균값을 가지고 있음을 알 수 있습니다. 작은 물체에 대한 분포는 큰 물체에 비해 center_y의 높은 값에 집중된 확률 밀도가 훨씬 큽니다. 이는 일반적으로 작은 물체가 큰 물체보다 center_y 값이 크다는 것을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
